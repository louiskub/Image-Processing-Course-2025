{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 4.1 Data Augmentation with PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `load_data()` function that loads the image using `ImageFolder()` with the specific `transforms.compose()` provided below.\n",
    "`load_data()` will return DataLoader() and print the information about the Dataset.\n",
    "\n",
    "`transforms.Compose()` :\n",
    "- `transforms.Resize()`\n",
    "- `transforms.ToTensor()`\n",
    "- `transforms.Pad()`\n",
    "- `transforms.RandomAffine(degrees=45, translate=(0.1, 0.1),scale=(0.8, 1.2), shear=45)`\n",
    "- `transforms.CenterCrop()`\n",
    "\n",
    "Resource : [`transforms.Compose()`](https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html#compose), [`torchvision.transforms v1`](<https://pytorch.org/vision/stable/transforms.html#v1-api-reference:~:text=custom)%20tv_tensor%20type.-,V1%20API%20Reference,-Geometry>), [`ImageFolder`](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html), [`Dataloader`](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#:~:text=Preparing%20your%20data%20for%20training%20with%20DataLoaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    ### START CODE HERE ###\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "\n",
    "    ])\n",
    "\n",
    "    dataset = ImageFolder(None)\n",
    "\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your load_data() function to load the dataset in the cell below. Then, display the image from the first batch.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "```\n",
    "ðŸ“ƒTrain Dataset:\n",
    "\tNumber of images in class battleship: 44\n",
    "\tNumber of images in class patrol boat: 35\n",
    "\tNumber of images in class submarine: 35\n",
    "\tNumber of samples: 114\n",
    "```\n",
    "\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/blob/main/Lab4_NN-and-CNN/assets/01.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "data_loader = load_data(None)\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create your own `CustomImageDataset` that performs the augmentation as in the previous section, but also includes the methods `add_gaussian_blur()` and `add_gaussian_noise()`. **<font color=\"red\">DO NOT</font>** use `transforms.Compose()`.\n",
    "\n",
    "Resource : [CustomImageDataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#:~:text=.show()-,Dataset%20class,-torch.utils.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = None\n",
    "        label = None\n",
    "        return image,label\n",
    "    \n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your `CustomImageDataset()` function. Then, display the image from the first batch.\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image-2.png](https://github.com/Digital-Image-Processing-Laboratory/Image-Processing-Course-2025/blob/main/Lab4_NN-and-CNN/assets/02.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "dataset = CustomImageDataset(None)\n",
    "dataloader = DataLoader(None)\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "1. Discuss effects and benefits of fill_mode or padding_mode.\n",
    "2. What would be amount of augmentation should be so that it would not effect the training performance?\n",
    "3. How can we create Salt-and-Pepper Noise, which is the type that greatly affect the image quality?\n",
    "4. What would be transform parameter to simulate camera lense effect?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
